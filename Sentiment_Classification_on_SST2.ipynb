{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwickban/Sentiment-Classification/blob/main/Sentiment_Classification_on_SST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9BGmIja3eUM"
      },
      "source": [
        "# Sentiment Classification on SST2 data set\n",
        "This notebook is taken from the Huggingface website (https://huggingface.co/docs/transformers/tasks/sequence_classification), modified for CSCI5541 and used for as a template for the homework assignment. Today we will be:\n",
        "1. Finetuning [Roberta](https://huggingface.co/distilbert-base-uncased) on the [SST2](https://huggingface.co/datasets/imdb) dataset to determine whether a given text is positive or negative.\n",
        "2. Using the finetuned model for inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI_Q_82C04Fj"
      },
      "source": [
        "### 1. Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PId_tPwn04Fb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Use this only after you check everything is being loaded properly\n",
        "\n",
        "# First install necessary libraries\n",
        "# Exclamation marks for shell commands\n",
        "! pip install transformers datasets evaluate scikit-learn\n",
        "! pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3h75_cVPUALs",
        "outputId": "57227e1d-a078-4c4b-d214-d6cc48ce9543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGfa9UU404Fj"
      },
      "source": [
        "We will be using the SST2 dataset from the Hugging Face Datasets library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OBxjgwN404Fk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sst2 = load_dataset('sst2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na0AWYQ504Fp"
      },
      "source": [
        "The dataset is separated into three sections: \"train,\" \"validation,\" and \"test\". We'll use the data in the \"train\" section for training, and you'll use the data in the \"validation\" section to evaluate your model. (The \"test\" data is labeled differently, so we will be using it to predict and check our model performance.)\n",
        "\n",
        "There are two fields in this dataset:\n",
        "\n",
        "- `text`: the review text.\n",
        "- `label`: a value that is either `0` for a negative review or `1` for a positive sentiment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sst2['train'].num_rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNfFwEAAUZo9",
        "outputId": "4e117db9-dadb-4f15-81c6-c006b04c5a66"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67349"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gti-_jHj04Fo"
      },
      "source": [
        "Then take a look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "niBayIU804Fp",
        "outputId": "86307de1-b862-457f-a868-ae4dd3bb4e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 1, 'sentence': 'contains no wit , only labored gags ', 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sst2['train'][1]\n",
        "#sst2['train'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQsRfcgM04Fq"
      },
      "source": [
        "### 2. Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np4aPRrK04Fq"
      },
      "source": [
        "The next step is to load a tokenizer to preprocess the `text` field.\n",
        "A tokenizer converts text to a sequence of tokens, creating a numerical representation of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bdu3bE-204Fq",
        "outputId": "faf86a41-5917-499c-9681-48dc689243d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "distilbert-base-uncased\n",
            "['[CLS]', 'hello', 'everyone', '!', '!', 'anti', '##dis', '##est', '##ab', '##lish', '##ment', '##arian', '##ism', '[SEP]']\n",
            "\n",
            "\n",
            "bert-base-cased\n",
            "['[CLS]', 'Hello', 'everyone', '!', '!', 'anti', '##dis', '##esta', '##b', '##lish', '##ment', '##arian', '##ism', '[SEP]']\n",
            "\n",
            "\n",
            "roberta-base\n",
            "['<s>', 'Hello', 'ƒ†everyone', '!', 'ƒ†!', 'ƒ†ant', 'idis', 'establishment', 'arian', 'ism', '</s>']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "distilbert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "bert_cased_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "#T5_base_tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
        "\n",
        "text = 'Hello everyone! ! antidisestablishmentarianism'\n",
        "\n",
        "for tokenizer in [distilbert_tokenizer, bert_cased_tokenizer, roberta_tokenizer]:\n",
        "  print(f'\\n\\n{tokenizer.name_or_path}')\n",
        "  vocab = {v: k for k, v in tokenizer.vocab.items()}\n",
        "  tokenized_text = tokenizer(text)\n",
        "  print([vocab[id] for id in tokenized_text['input_ids']])\n",
        "\n",
        "tokenizer = roberta_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcNyL85X04Fr"
      },
      "source": [
        "Here we will be using Roberta tokenizer, as going forward that will be our model of choice. It is necessary to have the same tokenizer as our model would expect the input to be in a certain way, Using the same tokenizer, helps in that regard. Creating a preprocessing function to tokenize `text`. we will specify how to deal with varying input lengths here using the max_length, truncation, and/or padding arguments. (Default is to not truncate or pad. Max length is determined by model.)\n",
        "\n",
        "https://huggingface.co/docs/transformers/pad_truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zX3n3XkK04Fr"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['sentence'], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UA_4n9k04Fr"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use ü§ó Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. We will speed up `map` by setting `batched=True` to process multiple elements of the dataset at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sEFf9WR004Fs",
        "outputId": "9b8a0978-0dd5-4917-c569-f231dc91d20f",
        "colab": {
          "referenced_widgets": [
            "43f89d77da0a43cdb3481d4934e6b772",
            "7c3137b031964cebbea4471c1559a8dd",
            "b3aa227d6f614e40a309a8ed742bf2fd",
            "25110160925d4a2c9dedb5a9742ca596",
            "8b1e1b0a1d6c4d1d9c3f17f524da6f4b",
            "7225d8261603425ea41df415655af06e",
            "932d7149373f4f40b0f461638fa213bf",
            "d7cdc4e59a1447c8a0f351c6bd6a59d7",
            "a4d49bcb05ae40fcb0bea787f9636034",
            "5d92f388dc7a4552bccd6348c9651db4",
            "7d897b99f65e4d6ca52e1d372c8ba7f2"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43f89d77da0a43cdb3481d4934e6b772"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_sst2 = sst2.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xft0YTM04Fs"
      },
      "source": [
        "Now we will create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximium length in the tokenzation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "C6LlGWc904Fs"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Maw8-j04Fs"
      },
      "source": [
        "### 3. Create evaluation method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjqByLvi04Fs"
      },
      "source": [
        "Including a metric during training is often helpful for evaluating our model's performance (otherwise, it just prints the loss). Therefore, we will load a evaluation method with the Hugging Face [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, we will load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "OSZAST_q04Ft"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "# Proportion of correct predictions among the total number of cases processed\n",
        "accuracy = evaluate.load('accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZErrBem04Ft"
      },
      "source": [
        "Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yRsPN52Z04Ft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07s2XRe04Ft"
      },
      "source": [
        "Our `compute_metrics` function is set up. Now,  -- we'll need it later when you set up our training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux-h7VOU04Fu"
      },
      "source": [
        "### 4. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWqaFM904Fu"
      },
      "source": [
        "Before we start training your model, we have to create a map of the expected ids to their labels with `id2label` and `label2id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "uMS7o3Ce04Fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0651def5-e72b-4933-c947-89013a519c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id2label: {0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "label2id: {'NEGATIVE': 0, 'POSITIVE': 1}\n"
          ]
        }
      ],
      "source": [
        "labels = ['NEGATIVE', 'POSITIVE']\n",
        "id2label = {i: label for i, label in enumerate(labels)}\n",
        "label2id = {label: i for i, label in id2label.items()}\n",
        "\n",
        "print('id2label:', id2label)\n",
        "print('label2id:', label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udEnVQh604Fu"
      },
      "source": [
        "Next, we will be using the Trainer class, which is wrapper code that abstracts away the details of training and evaluation. It is optimized for training Hugging Face Transformers and makes it easier for us to train models without writing much code.\n",
        "\n",
        "[Here is where I learnt about Transformers](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)<br/>\n",
        "[Another Transformers tutorial that helped](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "W-p8T7vF04Fu",
        "outputId": "b108369e-de6c-41fd-a4c3-cd1bd1b9370c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# This automodel class gives us the model with pretrained weights + a sequence classification head\n",
        "# We specify how many labels we need so that the model has the correct number of outputs\n",
        "# We specify id2label/label2id so that the model understands the label associated with each output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", num_labels=len(labels), id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLyVISQs04Fu"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Defining our training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the accuracy and save the training checkpoint.\n",
        "2. Passing the training arguments to our [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n",
        "3. Call the [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qkXa31kR04Fv"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/transformers/v4.4.2/main_classes/trainer.html#trainingarguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='Ritwickban/Roberta_SST2',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=49,\n",
        "    per_device_eval_batch_size=49,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sst2['validation']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icqM90jdf2VU",
        "outputId": "b1c7a0e6-ca62-4432-b598-4fbdaa261e98"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 872\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time as time\n",
        "import math\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "9jzhE5QJxmc8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are importing the required libraries for our model to run."
      ],
      "metadata": {
        "id": "nGwxeK1sNic7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-CaGMCeCFkB",
        "outputId": "303ef4b3-ccf3-4e3c-a411-501869a89c6d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUyC8p47CChC",
        "outputId": "ba90a599-8601-4341-bb92-53e2ab5e23b4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the library Weights and Biases, to log the metrics for our model training and evaluation parts of our model"
      ],
      "metadata": {
        "id": "EbtYg1JVN3Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTrainer(Trainer):\n",
        "  def _inner_training_loop(self, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None):\n",
        "        number_of_epochs = args.num_train_epochs\n",
        "        #number_of_train_batches = sst2['train'].num_rows/args.per_device_train_batch_size\n",
        "        start = time.time()\n",
        "        train_acc=[]\n",
        "        eval_acc=[]\n",
        "        criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer , 1, gamma=0.9)\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "        eval_dataloader = self.get_eval_dataloader()\n",
        "        # train\n",
        "        wandb.init(project=\"sst2\", name=\"ritwick\",\n",
        "        config=\n",
        "        {\"learning_rate\":2e-5 ,\n",
        "      \"architecture\": \"roberta-base\",\n",
        "      \"dataset\": \"SST2\",\n",
        "      \"epochs\": 2})\n",
        "        for epoch in range(number_of_epochs):\n",
        "            train_loss_per_epoch = 0\n",
        "            train_acc_per_epoch = 0\n",
        "            with tqdm(train_dataloader , unit=\"batch\") as training_epoch:\n",
        "                training_epoch.set_description(f\"Training Epoch {epoch}\")\n",
        "                for step, inputs in enumerate(training_epoch):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = inputs['labels']\n",
        "                    # forward pass\n",
        "                    self.optimizer.zero_grad()\n",
        "                    output = model(**inputs) # TODO Implement by yourself\n",
        "                    # get the loss\n",
        "                    loss = criterion(output['logits'], labels) # TODO Implement by yourself\n",
        "                    train_loss_per_epoch += loss.item()\n",
        "                    #calculate gradients\n",
        "                    loss.backward()\n",
        "                    #update weights\n",
        "                    self.optimizer.step()\n",
        "                    train_acc_per_epoch += (output['logits'].argmax(1) == labels).sum().item()\n",
        "                    wandb.log({\"train_acc\": train_acc_per_epoch, \"Train_loss\": train_loss_per_epoch})\n",
        "                    # adjust the learning rate\n",
        "            self.scheduler.step()\n",
        "            train_loss_per_epoch /= len(train_dataloader)\n",
        "            train_acc_per_epoch /= (len(train_dataloader)*batch_size)\n",
        "            #wandb.log({\"train_acc\": train_acc_per_epoch, \"Train_loss\": train_loss_per_epoch})\n",
        "\n",
        "            eval_loss_per_epoch = 0\n",
        "            eval_acc_per_epoch = 0\n",
        "            # evaluate on validation set\n",
        "            with torch.no_grad():\n",
        "                with tqdm(eval_dataloader , unit=\"batch\") as eval_epoch:\n",
        "                    eval_epoch.set_description(f\"Evaluation Epoch {epoch}\")\n",
        "                    for e_step, e_inputs in enumerate(eval_epoch):\n",
        "                        e_inputs = e_inputs.to(device)\n",
        "                        e_labels = e_inputs['labels']\n",
        "                        e_output = model(**e_inputs)\n",
        "                        loss = criterion(e_output['logits'], e_labels)\n",
        "                        eval_loss_per_epoch += loss.item()\n",
        "                        eval_acc_per_epoch += (e_output['logits'].argmax(1) == e_labels).sum().item()\n",
        "                        wandb.log({\"Eval_acc\": eval_acc_per_epoch, \"Eval_loss\": eval_loss_per_epoch})\n",
        "            eval_loss_per_epoch /= len(eval_dataloader)\n",
        "            eval_acc_per_epoch /= (len(eval_dataloader)*batch_size)\n",
        "            wandb.log({\"Eval_acc\": eval_acc_per_epoch, \"Eval_loss\": eval_loss_per_epoch})\n",
        "\n",
        "            print(f'\\tTrain Loss: {train_loss_per_epoch:.3f} | Train Acc: {train_acc_per_epoch*100:.2f}%')\n",
        "            print(f'\\tEval Loss: {eval_loss_per_epoch:.3f} | Eval Acc: {eval_acc_per_epoch*100:.2f}%')\n",
        "\n",
        "        print(f'Time: {(time.time()-start)/60:.3f} minutes')"
      ],
      "metadata": {
        "id": "zrMoTMTGgB3Z"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the custom trainer, to modify the inner training loop based on our requirements. and inheriting the rest of the trainer() class from Hugging face library. Then leveraging the train() from the trainer class to train our model."
      ],
      "metadata": {
        "id": "CFTTMKDOOeNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mytrainer = MyTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sst2['train'],\n",
        "    eval_dataset=tokenized_sst2['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "hU4-DplG4LSP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytrainer.train()"
      ],
      "metadata": {
        "id": "BS57YCfdnLCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557,
          "referenced_widgets": [
            "e1d188a022a64b368d6e322f03a353e5",
            "1e7fb368be9841df944bb78a3b11ef50",
            "980cc24295614e1c93d0116c754d8d39",
            "2b80da94f4b94659b2ef906311381ed2",
            "3204f4664cd444bc8b9cff6f0419074c",
            "54736313d41749f19c06c899541da142",
            "0360e28b7e844cfea5d9f65a51077a72",
            "f3e2bf5c6ea84d1b884aeb2a4bd12917"
          ]
        },
        "outputId": "a7b9faf5-d40a-413b-dfad-05ad26e6f4a5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:hr5dq670) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1d188a022a64b368d6e322f03a353e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Eval_acc</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÅ</td></tr><tr><td>Eval_loss</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÅ</td></tr><tr><td>Train_loss</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Eval_acc</td><td>0.92517</td></tr><tr><td>Eval_loss</td><td>0.18058</td></tr><tr><td>Train_loss</td><td>127.85197</td></tr><tr><td>train_acc</td><td>65163</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ritwick</strong> at: <a href='https://wandb.ai/ritwick/sst2/runs/hr5dq670' target=\"_blank\">https://wandb.ai/ritwick/sst2/runs/hr5dq670</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240211_223236-hr5dq670/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:hr5dq670). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240211_235551-xfn99962</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ritwick/sst2/runs/xfn99962' target=\"_blank\">ritwick</a></strong> to <a href='https://wandb.ai/ritwick/sst2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ritwick/sst2' target=\"_blank\">https://wandb.ai/ritwick/sst2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ritwick/sst2/runs/xfn99962' target=\"_blank\">https://wandb.ai/ritwick/sst2/runs/xfn99962</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 0:   0%|          | 0/1375 [00:00<?, ?batch/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Training Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [08:07<00:00,  2.82batch/s]\n",
            "Evaluation Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:02<00:00,  7.24batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.197 | Train Acc: 92.39%\n",
            "\tEval Loss: 0.162 | Eval Acc: 93.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375/1375 [08:05<00:00,  2.83batch/s]\n",
            "Evaluation Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:02<00:00,  7.23batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.094 | Train Acc: 96.74%\n",
            "\tEval Loss: 0.181 | Eval Acc: 92.63%\n",
            "Time: 16.423 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = model\n",
        "evaluation_results_trainer = mytrainer.evaluate(tokenized_sst2[\"validation\"])\n",
        "evaluation_results_trainer"
      ],
      "metadata": {
        "id": "hFsT7P-vIH4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d10e0f31-fa57-4c18-bef2-8d5d25d35df9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.1812105029821396,\n",
              " 'eval_accuracy': 0.9369266055045872,\n",
              " 'eval_runtime': 2.5086,\n",
              " 'eval_samples_per_second': 347.609,\n",
              " 'eval_steps_per_second': 7.175}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "i=0\n",
        "model_name=\"Roberta_SST2_Ritwick\"\n",
        "tokenizer = tokenizer\n",
        "model = model\n",
        "validation=tokenized_sst2['validation']\n",
        "while count!=10:\n",
        "  text=validation['sentence'][i]\n",
        "  inputs = tokenizer(text,return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "    inputs = inputs.to(device)\n",
        "    logits = model(**inputs).logits\n",
        "  predicted_class_id = logits.argmax().item()\n",
        "  if predicted_class_id!=validation['label'][i]:\n",
        "    print(text)\n",
        "    print('Confidence score:',torch.nn.functional.softmax(logits,dim=1))\n",
        "    print('Predict:',model.config.id2label[predicted_class_id],\"->Actual:\",model.config.id2label[validation['label'][i]])\n",
        "    count+=1\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "y-tpH56d8Ocl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17b5bf4-ab1c-4186-b9ce-5ca44fe87e9d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . \n",
            "Confidence score: tensor([[0.6872, 0.3128]], device='cuda:0')\n",
            "Predict: NEGATIVE ->Actual: POSITIVE\n",
            "holden caulfield did it better . \n",
            "Confidence score: tensor([[0.4957, 0.5043]], device='cuda:0')\n",
            "Predict: POSITIVE ->Actual: NEGATIVE\n",
            "the script kicks in , and mr. hartley 's distended pace and foot-dragging rhythms follow . \n",
            "Confidence score: tensor([[0.3453, 0.6547]], device='cuda:0')\n",
            "Predict: POSITIVE ->Actual: NEGATIVE\n",
            "fresnadillo 's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that wo n't go away . \n",
            "Confidence score: tensor([[0.6718, 0.3282]], device='cuda:0')\n",
            "Predict: NEGATIVE ->Actual: POSITIVE\n",
            "you wo n't like roger , but you will quickly recognize him . \n",
            "Confidence score: tensor([[0.0042, 0.9958]], device='cuda:0')\n",
            "Predict: POSITIVE ->Actual: NEGATIVE\n",
            "if steven soderbergh 's ` solaris ' is a failure it is a glorious failure . \n",
            "Confidence score: tensor([[0.9972, 0.0028]], device='cuda:0')\n",
            "Predict: NEGATIVE ->Actual: POSITIVE\n",
            "this riveting world war ii moral suspense story deals with the shadow side of american culture : racial prejudice in its ugly and diverse forms . \n",
            "Confidence score: tensor([[0.0161, 0.9839]], device='cuda:0')\n",
            "Predict: POSITIVE ->Actual: NEGATIVE\n",
            "does paint some memorable images ... , but makhmalbaf keeps her distance from the characters \n",
            "Confidence score: tensor([[0.7568, 0.2432]], device='cuda:0')\n",
            "Predict: NEGATIVE ->Actual: POSITIVE\n",
            "hilariously inept and ridiculous . \n",
            "Confidence score: tensor([[0.9876, 0.0124]], device='cuda:0')\n",
            "Predict: NEGATIVE ->Actual: POSITIVE\n",
            "sam mendes has become valedictorian at the school for soft landings and easy ways out . \n",
            "Confidence score: tensor([[0.1002, 0.8998]], device='cuda:0')\n",
            "Predict: POSITIVE ->Actual: NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeQDEJ5F04Fv"
      },
      "source": [
        "For a more in-depth example of how to finetune a model for text classification, I refererred the following sources:</br>\n",
        "[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)\n",
        "or [TensorFlow notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g43teU8y04Fw"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JghYtRta04Fw"
      },
      "source": [
        "Great, now that we've finetuned a model, we can use it for inference!\n",
        "\n",
        "We can use the test dataset to run inference on our model and training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1Va0KfJw04Fw"
      },
      "outputs": [],
      "source": [
        "text=sst2['test']['sentence']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6pr6ISuJKa1q"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(sst2['test'],columns=['sentence','label'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NS6XVdeFKWx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "61dd462c-c8a2-4cb5-aa05-0d17cc19adad"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  label\n",
              "0             uneasy mishmash of styles and genres .     -1\n",
              "1  this film 's relationship to actual tension is...     -1\n",
              "2  by the end of no such thing the audience , lik...     -1\n",
              "3  director rob marshall went out gunning to make...     -1\n",
              "4  lathan and diggs have considerable personal ch...     -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61d09469-8bd5-4eb4-90e0-b83816c84661\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uneasy mishmash of styles and genres .</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this film 's relationship to actual tension is...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>by the end of no such thing the audience , lik...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>director rob marshall went out gunning to make...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lathan and diggs have considerable personal ch...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61d09469-8bd5-4eb4-90e0-b83816c84661')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61d09469-8bd5-4eb4-90e0-b83816c84661 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61d09469-8bd5-4eb4-90e0-b83816c84661');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6595dc4f-cf9a-4c17-9071-ac473d3715d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6595dc4f-cf9a-4c17-9071-ac473d3715d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6595dc4f-cf9a-4c17-9071-ac473d3715d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm1YKzjU04Fw"
      },
      "source": [
        "To try out your finetuned model for inference lets use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiating a `pipeline` for sentiment analysis with your model, and pass our text to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "iVwU3DiB04Fw"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=device)\n",
        "#classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['prediction']=classifier(text)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RxFWwqPUKHQY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6654f75f-c6fa-4e67-88aa-c0f80b1865d3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  label  \\\n",
              "0             uneasy mishmash of styles and genres .     -1   \n",
              "1  this film 's relationship to actual tension is...     -1   \n",
              "2  by the end of no such thing the audience , lik...     -1   \n",
              "3  director rob marshall went out gunning to make...     -1   \n",
              "4  lathan and diggs have considerable personal ch...     -1   \n",
              "\n",
              "                                          prediction  \n",
              "0  {'label': 'NEGATIVE', 'score': 0.9868481755256...  \n",
              "1  {'label': 'NEGATIVE', 'score': 0.9963800311088...  \n",
              "2  {'label': 'POSITIVE', 'score': 0.8997088074684...  \n",
              "3  {'label': 'POSITIVE', 'score': 0.9586588144302...  \n",
              "4  {'label': 'POSITIVE', 'score': 0.9986604452133...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-530715b3-2111-4ab2-a54c-a70ccf63210a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uneasy mishmash of styles and genres .</td>\n",
              "      <td>-1</td>\n",
              "      <td>{'label': 'NEGATIVE', 'score': 0.9868481755256...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this film 's relationship to actual tension is...</td>\n",
              "      <td>-1</td>\n",
              "      <td>{'label': 'NEGATIVE', 'score': 0.9963800311088...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>by the end of no such thing the audience , lik...</td>\n",
              "      <td>-1</td>\n",
              "      <td>{'label': 'POSITIVE', 'score': 0.8997088074684...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>director rob marshall went out gunning to make...</td>\n",
              "      <td>-1</td>\n",
              "      <td>{'label': 'POSITIVE', 'score': 0.9586588144302...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lathan and diggs have considerable personal ch...</td>\n",
              "      <td>-1</td>\n",
              "      <td>{'label': 'POSITIVE', 'score': 0.9986604452133...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-530715b3-2111-4ab2-a54c-a70ccf63210a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-530715b3-2111-4ab2-a54c-a70ccf63210a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-530715b3-2111-4ab2-a54c-a70ccf63210a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecff18c1-a82f-40cd-b5f9-ce7c34d8dd11\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecff18c1-a82f-40cd-b5f9-ce7c34d8dd11')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecff18c1-a82f-40cd-b5f9-ce7c34d8dd11 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_prediction(prediction):\n",
        "    sentiment = prediction['label']\n",
        "    score = prediction['score']\n",
        "    return sentiment, score\n",
        "\n",
        "# Apply the function to the prediction column and assign results to new columns\n",
        "df[['Sentiment', 'Score']] = df['prediction'].apply(lambda x: pd.Series(parse_prediction(x)))\n"
      ],
      "metadata": {
        "id": "rxST7-QlLqnp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TzwnzSHrcsk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Toev6FPb7MA",
        "outputId": "16be3a4c-7df7-41a4-d29a-739336f0bfdc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "df.to_csv(\"Annotated.csv\")\n",
        "files.download(\"Annotated.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9zOTO6Msrte1",
        "outputId": "cf460b3a-798a-48d4-c2b7-f38f0502322c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cbd0a07d-8f8b-4370-ba3c-0a78514db469\", \"Annotated.csv\", 351839)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1HTgu2KLneZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nd092nB04Fx"
      },
      "source": [
        "Here, lets have the predictions on the basis of the sentences in our test dataset, and then append it to our test dataset, and have the predictions along with it, hence we can annotate and figure out errors our model is making"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGBjF24gkDg0"
      },
      "source": [
        "## Here are few resources that helped in completing this project!\n",
        "### Model/Dateset Cards in Huggingface (Documentation)\n",
        "\n",
        "Markdown files with information on how to use the model/dataset and other relevant data (metadata, potential limitations, etc.)\n",
        "\n",
        "Looking for models/datasets to use:<br/>\n",
        "https://huggingface.co/models<br/>\n",
        "https://huggingface.co/datasets\n",
        "\n",
        "More information:<br/>\n",
        "https://huggingface.co/docs/hub/model-cards<br/>\n",
        "https://huggingface.co/docs/hub/datasets-cards\n",
        "\n",
        "Templates:<br/>\n",
        "https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md<br/>\n",
        "https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/datasetcard_template.md\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43f89d77da0a43cdb3481d4934e6b772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c3137b031964cebbea4471c1559a8dd",
              "IPY_MODEL_b3aa227d6f614e40a309a8ed742bf2fd",
              "IPY_MODEL_25110160925d4a2c9dedb5a9742ca596"
            ],
            "layout": "IPY_MODEL_8b1e1b0a1d6c4d1d9c3f17f524da6f4b"
          }
        },
        "7c3137b031964cebbea4471c1559a8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7225d8261603425ea41df415655af06e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_932d7149373f4f40b0f461638fa213bf",
            "value": "Map: 100%"
          }
        },
        "b3aa227d6f614e40a309a8ed742bf2fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7cdc4e59a1447c8a0f351c6bd6a59d7",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4d49bcb05ae40fcb0bea787f9636034",
            "value": 872
          }
        },
        "25110160925d4a2c9dedb5a9742ca596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d92f388dc7a4552bccd6348c9651db4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7d897b99f65e4d6ca52e1d372c8ba7f2",
            "value": " 872/872 [00:00&lt;00:00, 7804.99 examples/s]"
          }
        },
        "8b1e1b0a1d6c4d1d9c3f17f524da6f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7225d8261603425ea41df415655af06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932d7149373f4f40b0f461638fa213bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7cdc4e59a1447c8a0f351c6bd6a59d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d49bcb05ae40fcb0bea787f9636034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d92f388dc7a4552bccd6348c9651db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d897b99f65e4d6ca52e1d372c8ba7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1d188a022a64b368d6e322f03a353e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e7fb368be9841df944bb78a3b11ef50",
              "IPY_MODEL_980cc24295614e1c93d0116c754d8d39"
            ],
            "layout": "IPY_MODEL_2b80da94f4b94659b2ef906311381ed2"
          }
        },
        "1e7fb368be9841df944bb78a3b11ef50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3204f4664cd444bc8b9cff6f0419074c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_54736313d41749f19c06c899541da142",
            "value": "0.016 MB of 0.016 MB uploaded\r"
          }
        },
        "980cc24295614e1c93d0116c754d8d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0360e28b7e844cfea5d9f65a51077a72",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3e2bf5c6ea84d1b884aeb2a4bd12917",
            "value": 1
          }
        },
        "2b80da94f4b94659b2ef906311381ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3204f4664cd444bc8b9cff6f0419074c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54736313d41749f19c06c899541da142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0360e28b7e844cfea5d9f65a51077a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3e2bf5c6ea84d1b884aeb2a4bd12917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}